{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045d66da",
   "metadata": {},
   "source": [
    "# Table 1: Characteristics of Training and Test Datasets\n",
    "\n",
    "This notebook creates a comprehensive Table 1 summarizing the characteristics of the training and test datasets used for the XGBoost insufficient pain management prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the parent directory to the path\n",
    "sys.path.append('/Users/jk1/icu_research/PreHosp')\n",
    "\n",
    "from analgesia.prediction_of_insufficient_pain_management.data_preprocessing import load_and_preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff343ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "print(\"üìä Loading and preprocessing data for Table 1 analysis...\")\n",
    "data_path = '/Users/jk1/Library/CloudStorage/OneDrive-unige.ch/icu_research/prehospital/analgesia/data/trauma_categories_Rega Pain Study15.09.2025_v2.xlsx'\n",
    "processed_data, processor = load_and_preprocess_data(data_path)\n",
    "\n",
    "# Get the modeling data splits\n",
    "X_train, X_test, y_train, y_test = processor.prepare_modeling_data()\n",
    "\n",
    "print(f\"‚úÖ Data loaded:\")\n",
    "print(f\"   Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"   Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"   Total features: {X_train.shape[1]}\")\n",
    "\n",
    "# Combine training data with targets for analysis\n",
    "train_data = X_train.copy()\n",
    "train_data['insufficient_pain_mgmt'] = y_train\n",
    "train_data['dataset'] = 'Training'\n",
    "\n",
    "test_data = X_test.copy()\n",
    "test_data['insufficient_pain_mgmt'] = y_test\n",
    "test_data['dataset'] = 'Test'\n",
    "\n",
    "# Combine for overall statistics\n",
    "all_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "print(f\"\\nüìã Target distribution:\")\n",
    "print(f\"   Training - Adequate: {(y_train == 0).sum()}, Insufficient: {(y_train == 1).sum()}\")\n",
    "print(f\"   Test - Adequate: {(y_test == 0).sum()}, Insufficient: {(y_test == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data to get additional clinical variables not in the model features\n",
    "original_data = pd.read_excel(data_path)\n",
    "\n",
    "# Create the insufficient pain management target for original data\n",
    "original_data['VAS_change'] = original_data['VAS_on_arrival'] - original_data['VAS_on_scene']\n",
    "original_data['VAS_improved'] = original_data['VAS_change'] < 0\n",
    "original_data['insufficient_pain_mgmt'] = (\n",
    "    (original_data['VAS_on_arrival'] >= 4) | \n",
    "    (~original_data['VAS_improved'] & (original_data['VAS_on_scene'] >= 4))\n",
    ").astype(float)\n",
    "\n",
    "# Remove cases with missing target\n",
    "original_data = original_data[original_data['insufficient_pain_mgmt'].notna()]\n",
    "\n",
    "print(f\"üìã Original dataset: {len(original_data)} cases with complete target information\")\n",
    "print(f\"   Matches processed data: {len(original_data) == len(all_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e511da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions for creating Table 1 statistics\n",
    "\n",
    "def get_continuous_stats(data, column, dataset=None):\n",
    "    \"\"\"Get mean ¬± SD for continuous variables.\"\"\"\n",
    "    if dataset:\n",
    "        subset = data[data['dataset'] == dataset]\n",
    "    else:\n",
    "        subset = data\n",
    "    \n",
    "    if column not in subset.columns:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    values = subset[column].dropna()\n",
    "    if len(values) == 0:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    mean_val = values.mean()\n",
    "    std_val = values.std()\n",
    "    n_val = len(values)\n",
    "    n_missing = len(subset) - len(values)\n",
    "    \n",
    "    if n_missing > 0:\n",
    "        return f\"{mean_val:.1f} ¬± {std_val:.1f} (n={n_val}, missing={n_missing})\"\n",
    "    else:\n",
    "        return f\"{mean_val:.1f} ¬± {std_val:.1f}\"\n",
    "\n",
    "def get_categorical_stats(data, column, category=None, dataset=None):\n",
    "    \"\"\"Get n (%) for categorical variables.\"\"\"\n",
    "    if dataset:\n",
    "        subset = data[data['dataset'] == dataset]\n",
    "    else:\n",
    "        subset = data\n",
    "    \n",
    "    if column not in subset.columns:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    total_n = len(subset)\n",
    "    \n",
    "    if category is not None:\n",
    "        # Specific category\n",
    "        if isinstance(category, (list, tuple)):\n",
    "            count = subset[column].isin(category).sum()\n",
    "        else:\n",
    "            count = (subset[column] == category).sum()\n",
    "    else:\n",
    "        # For binary variables, count non-zero/True values\n",
    "        count = subset[column].sum() if subset[column].dtype in ['bool', 'int64', 'float64'] else len(subset[column].dropna())\n",
    "    \n",
    "    percentage = (count / total_n) * 100\n",
    "    return f\"{count} ({percentage:.1f}%)\"\n",
    "\n",
    "def get_p_value(data, column, is_continuous=True):\n",
    "    \"\"\"Calculate p-value comparing training vs test sets.\"\"\"\n",
    "    if column not in data.columns:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    train_vals = data[data['dataset'] == 'Training'][column].dropna()\n",
    "    test_vals = data[data['dataset'] == 'Test'][column].dropna()\n",
    "    \n",
    "    if len(train_vals) == 0 or len(test_vals) == 0:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    try:\n",
    "        if is_continuous:\n",
    "            # Use t-test for continuous variables\n",
    "            statistic, p_value = stats.ttest_ind(train_vals, test_vals)\n",
    "        else:\n",
    "            # Use chi-square test for categorical variables\n",
    "            train_count = train_vals.sum() if train_vals.dtype in ['bool', 'int64', 'float64'] else len(train_vals)\n",
    "            test_count = test_vals.sum() if test_vals.dtype in ['bool', 'int64', 'float64'] else len(test_vals)\n",
    "            train_total = len(train_vals)\n",
    "            test_total = len(test_vals)\n",
    "            \n",
    "            contingency_table = np.array([\n",
    "                [train_count, train_total - train_count],\n",
    "                [test_count, test_total - test_count]\n",
    "            ])\n",
    "            \n",
    "            statistic, p_value, _, _ = stats.chi2_contingency(contingency_table)\n",
    "        \n",
    "        if p_value < 0.001:\n",
    "            return \"<0.001\"\n",
    "        elif p_value < 0.01:\n",
    "            return f\"{p_value:.3f}\"\n",
    "        else:\n",
    "            return f\"{p_value:.2f}\"\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table 1 structure\n",
    "table1_data = []\n",
    "\n",
    "# Dataset characteristics\n",
    "table1_data.append({\n",
    "    'Characteristic': 'Dataset Size',\n",
    "    'Overall': f\"{len(all_data)}\",\n",
    "    'Training': f\"{len(train_data)}\",\n",
    "    'Test': f\"{len(test_data)}\",\n",
    "    'P-value': \"N/A\"\n",
    "})\n",
    "\n",
    "# Target variable distribution\n",
    "table1_data.append({\n",
    "    'Characteristic': 'Insufficient Pain Management',\n",
    "    'Overall': get_categorical_stats(all_data, 'insufficient_pain_mgmt'),\n",
    "    'Training': get_categorical_stats(train_data, 'insufficient_pain_mgmt'),\n",
    "    'Test': get_categorical_stats(test_data, 'insufficient_pain_mgmt'),\n",
    "    'P-value': get_p_value(all_data, 'insufficient_pain_mgmt', is_continuous=False)\n",
    "})\n",
    "\n",
    "print(\"üìä Basic dataset characteristics added to table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1425c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vital signs (continuous variables) - using original unscaled data\n",
    "vital_signs = {\n",
    "    'Heart Rate (bpm)': 'HR',\n",
    "    'Heart Rate at 5 min (bpm)': 'HR5', \n",
    "    'Oxygen Saturation (%)': 'SPO2',\n",
    "    'Oxygen Saturation at 11 min (%)': 'SPO211',\n",
    "    'Glasgow Coma Scale': 'GCS',\n",
    "    'Glasgow Coma Scale at 7 min': 'GCS7',\n",
    "    'VAS Pain Score at Scene': 'VAS_on_scene'\n",
    "}\n",
    "\n",
    "for label, column in vital_signs.items():\n",
    "    table1_data.append({\n",
    "        'Characteristic': label,\n",
    "        'Overall': get_continuous_stats(orig_all_data, column),\n",
    "        'Training': get_continuous_stats(orig_all_data, column, 'Training'),\n",
    "        'Test': get_continuous_stats(orig_all_data, column, 'Test'),\n",
    "        'P-value': get_p_value(orig_all_data, column, is_continuous=True)\n",
    "    })\n",
    "\n",
    "print(\"üìà Vital signs added to table (using original unscaled values)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a76ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix: Use original unscaled data for vital signs to show actual clinical values\n",
    "# Create train/test splits from original data to match the modeling splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the same train/test split as used in modeling (using same random state)\n",
    "original_X = original_data.drop(['insufficient_pain_mgmt'], axis=1)\n",
    "original_y = original_data['insufficient_pain_mgmt']\n",
    "\n",
    "# Split with same parameters as in preprocessing\n",
    "orig_X_train, orig_X_test, orig_y_train, orig_y_test = train_test_split(\n",
    "    original_X, original_y, test_size=0.2, random_state=42, stratify=original_y\n",
    ")\n",
    "\n",
    "# Create original data with dataset labels\n",
    "orig_train_data = orig_X_train.copy()\n",
    "orig_train_data['insufficient_pain_mgmt'] = orig_y_train\n",
    "orig_train_data['dataset'] = 'Training'\n",
    "\n",
    "orig_test_data = orig_X_test.copy()\n",
    "orig_test_data['insufficient_pain_mgmt'] = orig_y_test\n",
    "orig_test_data['dataset'] = 'Test'\n",
    "\n",
    "# Combine for overall statistics\n",
    "orig_all_data = pd.concat([orig_train_data, orig_test_data], ignore_index=True)\n",
    "\n",
    "print(\"‚úÖ Original unscaled data prepared for vital signs display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild Table 1 with correct data - reset and start fresh\n",
    "table1_data = []\n",
    "\n",
    "# Dataset characteristics (using processed data for counts)\n",
    "table1_data.append({\n",
    "    'Characteristic': 'Dataset Size',\n",
    "    'Overall': f\"{len(all_data)}\",\n",
    "    'Training': f\"{len(train_data)}\",\n",
    "    'Test': f\"{len(test_data)}\",\n",
    "    'P-value': \"N/A\"\n",
    "})\n",
    "\n",
    "# Target variable distribution (using processed data)\n",
    "table1_data.append({\n",
    "    'Characteristic': 'Insufficient Pain Management',\n",
    "    'Overall': get_categorical_stats(all_data, 'insufficient_pain_mgmt'),\n",
    "    'Training': get_categorical_stats(train_data, 'insufficient_pain_mgmt'),\n",
    "    'Test': get_categorical_stats(test_data, 'insufficient_pain_mgmt'),\n",
    "    'P-value': get_p_value(all_data, 'insufficient_pain_mgmt', is_continuous=False)\n",
    "})\n",
    "\n",
    "print(\"üîÑ Table 1 data reset and basic characteristics re-added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cfaf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add categorical vital sign categories\n",
    "categorical_vitals = {\n",
    "    'Normal Heart Rate': 'HR_category_Normal',\n",
    "    'Tachycardia': 'HR_category_Tachycardia',\n",
    "    'Severe Tachycardia': 'HR_category_Severe_Tachycardia',\n",
    "    'Normal Oxygen Saturation': 'SPO2_category_Normal',\n",
    "    'Severe Hypoxia': 'SPO2_category_Severe_Hypoxia'\n",
    "}\n",
    "\n",
    "for label, column in categorical_vitals.items():\n",
    "    table1_data.append({\n",
    "        'Characteristic': label,\n",
    "        'Overall': get_categorical_stats(all_data, column),\n",
    "        'Training': get_categorical_stats(all_data, column, dataset='Training'),\n",
    "        'Test': get_categorical_stats(all_data, column, dataset='Test'),\n",
    "        'P-value': get_p_value(all_data, column, is_continuous=False)\n",
    "    })\n",
    "\n",
    "print(\"üìä Categorical vital signs added to table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf83aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add demographics and clinical factors\n",
    "demographics = {\n",
    "    'Female Gender': 'Geschlecht_Weiblich',\n",
    "    'Unknown Gender': 'Geschlecht_Unbekannt',\n",
    "    'No Resuscitation Performed': 'Ist Reanimation durchgef√ºhrt_Nein'\n",
    "}\n",
    "\n",
    "for label, column in demographics.items():\n",
    "    table1_data.append({\n",
    "        'Characteristic': label,\n",
    "        'Overall': get_categorical_stats(all_data, column),\n",
    "        'Training': get_categorical_stats(all_data, column, dataset='Training'),\n",
    "        'Test': get_categorical_stats(all_data, column, dataset='Test'),\n",
    "        'P-value': get_p_value(all_data, column, is_continuous=False)\n",
    "    })\n",
    "\n",
    "print(\"üë• Demographics added to table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23eeb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add chest tube drainage (medical interventions) - summarized\n",
    "chest_tube_columns = [col for col in all_data.columns if col.startswith('Thoraxdrainage_')]\n",
    "if chest_tube_columns:\n",
    "    # Create a summary variable for any chest tube drainage\n",
    "    all_data['any_chest_tube'] = all_data[chest_tube_columns].sum(axis=1) > 0\n",
    "    train_data['any_chest_tube'] = train_data[chest_tube_columns].sum(axis=1) > 0\n",
    "    test_data['any_chest_tube'] = test_data[chest_tube_columns].sum(axis=1) > 0\n",
    "    \n",
    "    table1_data.append({\n",
    "        'Characteristic': 'Any Chest Tube Drainage',\n",
    "        'Overall': get_categorical_stats(all_data, 'any_chest_tube'),\n",
    "        'Training': get_categorical_stats(all_data, 'any_chest_tube', dataset='Training'),\n",
    "        'Test': get_categorical_stats(all_data, 'any_chest_tube', dataset='Test'),\n",
    "        'P-value': get_p_value(all_data, 'any_chest_tube', is_continuous=False)\n",
    "    })\n",
    "\n",
    "print(f\"üè• Medical interventions added to table ({len(chest_tube_columns)} chest tube variables summarized)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa63d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final Table 1 DataFrame\n",
    "table1_df = pd.DataFrame(table1_data)\n",
    "\n",
    "# Display the table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã TABLE 1: Characteristics of Training and Test Datasets\")\n",
    "print(\"   XGBoost Model for Insufficient Pain Management Prediction\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Format the table for display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "\n",
    "display(table1_df)\n",
    "\n",
    "print(\"\\nüìä Summary Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total cases: {len(all_data):,}\")\n",
    "print(f\"   ‚Ä¢ Training set: {len(train_data):,} ({len(train_data)/len(all_data)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Test set: {len(test_data):,} ({len(test_data)/len(all_data)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Features used in model: {X_train.shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Insufficient pain management rate: {all_data['insufficient_pain_mgmt'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ca07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the table to CSV for further use\n",
    "csv_path = \"/Users/jk1/icu_research/PreHosp/analgesia/prediction_of_insufficient_pain_management/table1_model_datasets.csv\"\n",
    "table1_df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nüíæ Table 1 saved to: {csv_path}\")\n",
    "\n",
    "# Also save with formatting for publication\n",
    "formatted_table = table1_df.copy()\n",
    "formatted_table.columns = ['Variable', 'Overall (N=12,269)', 'Training (N=9,815)', 'Test (N=2,454)', 'P-value']\n",
    "\n",
    "publication_path = \"/Users/jk1/icu_research/PreHosp/analgesia/prediction_of_insufficient_pain_management/table1_formatted.csv\"\n",
    "formatted_table.to_csv(publication_path, index=False)\n",
    "print(f\"üìÑ Formatted table saved to: {publication_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show just the vital signs rows to verify the correction\n",
    "print(\"üîç CORRECTED VITAL SIGNS VALUES:\")\n",
    "print(\"=\"*50)\n",
    "vital_signs_rows = table1_df[table1_df['Characteristic'].str.contains('Rate|Saturation|Coma|VAS', na=False)]\n",
    "for _, row in vital_signs_rows.iterrows():\n",
    "    if any(keyword in row['Characteristic'] for keyword in ['Rate (bpm)', 'Saturation (%)', 'Coma Scale', 'VAS']):\n",
    "        print(f\"{row['Characteristic']:35}: {row['Overall']}\")\n",
    "        \n",
    "print(\"\\n‚úÖ Values now show actual clinical measurements instead of scaled values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674abff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional summary statistics for the paper\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìà ADDITIONAL SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall dataset characteristics\n",
    "print(\"\\nüè• Dataset Composition:\")\n",
    "print(f\"   ‚Ä¢ Total eligible cases: {len(all_data):,}\")\n",
    "print(f\"   ‚Ä¢ Training/Test split: {len(train_data):,} / {len(test_data):,} ({len(train_data)/len(all_data)*100:.0f}%/{len(test_data)/len(all_data)*100:.0f}%)\")\n",
    "print(f\"   ‚Ä¢ Random state: 42 (for reproducibility)\")\n",
    "\n",
    "# Target variable balance\n",
    "print(\"\\nüéØ Target Variable Distribution:\")\n",
    "overall_insufficient = all_data['insufficient_pain_mgmt'].sum()\n",
    "train_insufficient = train_data['insufficient_pain_mgmt'].sum()\n",
    "test_insufficient = test_data['insufficient_pain_mgmt'].sum()\n",
    "\n",
    "print(f\"   ‚Ä¢ Overall insufficient pain management: {overall_insufficient:,} ({overall_insufficient/len(all_data)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Training set: {train_insufficient:,} ({train_insufficient/len(train_data)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Test set: {test_insufficient:,} ({test_insufficient/len(test_data)*100:.1f}%)\")\n",
    "\n",
    "# Key clinical variables summary\n",
    "print(\"\\nüìä Key Clinical Variables (Overall):\")\n",
    "if 'VAS_on_scene' in all_data.columns:\n",
    "    vas_mean = all_data['VAS_on_scene'].mean()\n",
    "    vas_std = all_data['VAS_on_scene'].std()\n",
    "    print(f\"   ‚Ä¢ VAS at scene: {vas_mean:.1f} ¬± {vas_std:.1f}\")\n",
    "\n",
    "if 'GCS' in all_data.columns:\n",
    "    gcs_mean = all_data['GCS'].mean()\n",
    "    gcs_std = all_data['GCS'].std()\n",
    "    print(f\"   ‚Ä¢ Glasgow Coma Scale: {gcs_mean:.1f} ¬± {gcs_std:.1f}\")\n",
    "\n",
    "if 'HR' in all_data.columns:\n",
    "    hr_mean = all_data['HR'].mean()\n",
    "    hr_std = all_data['HR'].std()\n",
    "    print(f\"   ‚Ä¢ Heart Rate: {hr_mean:.0f} ¬± {hr_std:.0f} bpm\")\n",
    "\n",
    "if 'SPO2' in all_data.columns:\n",
    "    spo2_mean = all_data['SPO2'].mean()\n",
    "    spo2_std = all_data['SPO2'].std()\n",
    "    print(f\"   ‚Ä¢ Oxygen Saturation: {spo2_mean:.1f} ¬± {spo2_std:.1f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Table 1 analysis completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
